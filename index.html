<!DOCTYPE html>
<html lang="da">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kaotisk TV-sne med Tydelig Lydreaktion</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: black; }
        canvas { display: block; }
    </style>
</head>
<body>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script>
        let scene, camera, renderer, particles;
        let audioContext, analyser;
        const particleCount = 200000;
        let audioData, time = 0;
        let avgAudioLevel = 0;

        function init() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer();
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            const geometry = new THREE.BufferGeometry();
            const positions = new Float32Array(particleCount * 3);
            const randomness = new Float32Array(particleCount);

            for (let i = 0; i < particleCount * 3; i += 3) {
                positions[i] = (Math.random() - 0.5) * 4;
                positions[i + 1] = (Math.random() - 0.5) * 4;
                positions[i + 2] = (Math.random() - 0.5) * 4;
                randomness[i / 3] = Math.random();
            }

            geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
            geometry.setAttribute('randomness', new THREE.BufferAttribute(randomness, 1));

            const material = new THREE.ShaderMaterial({
                uniforms: {
                    audioData: { value: null },
                    time: { value: 0 },
                    avgAudioLevel: { value: 0 },
                    baseMovement: { value: 0.003 },
                    audioInfluence: { value: 0.02 }
                },
                vertexShader: `
                    uniform float time;
                    uniform sampler2D audioData;
                    uniform float avgAudioLevel;
                    uniform float baseMovement;
                    uniform float audioInfluence;
                    attribute float randomness;
                    varying vec3 vColor;

                    float noise(vec3 p) {
                        return fract(sin(dot(p, vec3(12.9898, 78.233, 45.5432))) * 43758.5453);
                    }

                    void main() {
                        float audioValue = texture2D(audioData, vec2(abs(position.x) * 0.25, 0.5)).r;
                        
                        vec3 newPosition = position;
                        float noiseValue = noise(position * 2.0 + time);
                        
                        // Base movement
                        newPosition += vec3(
                            sin(time * (3.0 + randomness * 2.0) + position.x * 5.0),
                            cos(time * (2.0 + randomness * 2.0) + position.y * 4.0),
                            sin(time * (2.5 + randomness * 2.0) + position.z * 4.5)
                        ) * baseMovement;
                        
                        // Audio-reactive movement
                        newPosition += vec3(
                            sin(audioValue * 10.0 + time * 5.0) * audioInfluence,
                            cos(audioValue * 8.0 + time * 4.0) * audioInfluence,
                            sin(audioValue * 9.0 + time * 4.5) * audioInfluence
                        ) * avgAudioLevel * 2.0;  // Amplify the effect

                        // Wrap-around effect
                        newPosition = fract(newPosition + 0.5) - 0.5;
                        newPosition *= 4.0;

                        vec4 mvPosition = modelViewMatrix * vec4(newPosition, 1.0);
                        gl_PointSize = 1.5 * (1.0 + audioValue * 3.0 + noiseValue);
                        gl_Position = projectionMatrix * mvPosition;

                        // Color based on audio level
                        float intensity = 0.3 + audioValue * 0.7 + noiseValue * 0.2;
                        vColor = mix(vec3(intensity), vec3(1.0, 0.5, 0.0), avgAudioLevel);  // Transition to orange for high audio levels
                    }
                `,
                fragmentShader: `
                    varying vec3 vColor;
                    void main() {
                        gl_FragColor = vec4(vColor, 1.0);
                    }
                `,
                transparent: true,
                blending: THREE.AdditiveBlending,
            });

            particles = new THREE.Points(geometry, material);
            scene.add(particles);

            camera.position.z = 2;

            renderer.domElement.addEventListener('click', toggleFullScreen);
            initAudio();
            animate();
        }

        function animate() {
            requestAnimationFrame(animate);
            time += 0.01;
            particles.material.uniforms.time.value = time;

            if (analyser) {
                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                analyser.getByteFrequencyData(dataArray);
                
                if (!audioData) {
                    audioData = new THREE.DataTexture(dataArray, 256, 1, THREE.RedFormat);
                }
                audioData.needsUpdate = true;
                particles.material.uniforms.audioData.value = audioData;

                // Smooth out the average audio level for more stable visual changes
                const instantAvg = dataArray.reduce((a, b) => a + b, 0) / dataArray.length / 255;
                avgAudioLevel = avgAudioLevel * 0.95 + instantAvg * 0.05;
                particles.material.uniforms.avgAudioLevel.value = avgAudioLevel;

                particles.material.uniforms.audioInfluence.value = 0.02 + avgAudioLevel * 0.1;
            }

            renderer.render(scene, camera);
        }

        function toggleFullScreen() {
            if (!document.fullscreenElement) {
                document.documentElement.requestFullscreen();
            } else {
                if (document.exitFullscreen) {
                    document.exitFullscreen();
                }
            }
        }

        function initAudio() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    analyser = audioContext.createAnalyser();
                    analyser.fftSize = 512;
                    const source = audioContext.createMediaStreamSource(stream);
                    source.connect(analyser);
                })
                .catch(err => console.error('Fejl ved adgang til mikrofon:', err));
        }

        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

        init();
    </script>
</body>
</html>
