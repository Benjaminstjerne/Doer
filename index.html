<!DOCTYPE html>
<html lang="da">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>lyd</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: black; }
        canvas { display: block; }
    </style>
</head>
<body>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script>
        let scene, camera, renderer, particles;
        let audioContext, analyser;
        const particleCount = 300000;
        let audioData, time = 0;
        let avgAudioLevel = 0;
        let peakLevel = 0;
        let lastAudioImpulse = 0;

        function init() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer();
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            const geometry = new THREE.BufferGeometry();
            const positions = new Float32Array(particleCount * 3);
            const randomness = new Float32Array(particleCount);

            for (let i = 0; i < particleCount * 3; i += 3) {
                positions[i] = (Math.random() - 0.5) * 4;
                positions[i + 1] = (Math.random() - 0.5) * 4;
                positions[i + 2] = (Math.random() - 0.5) * 4;
                randomness[i / 3] = Math.random();
            }

            geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
            geometry.setAttribute('randomness', new THREE.BufferAttribute(randomness, 1));

            const material = new THREE.ShaderMaterial({
                uniforms: {
                    audioData: { value: null },
                    time: { value: 0 },
                    avgAudioLevel: { value: 0 },
                    peakLevel: { value: 0 },
                    lastAudioImpulse: { value: 0 },
                    resolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) }
                },
                vertexShader: `
                    uniform float time;
                    uniform float avgAudioLevel;
                    uniform float peakLevel;
                    uniform float lastAudioImpulse;
                    uniform vec2 resolution;
                    attribute float randomness;
                    varying vec2 vUv;
                    varying float vRandomness;

                    void main() {
                        vUv = uv;
                        vRandomness = randomness;
                        
                        vec3 newPosition = position;
                        
                        // Subtle constant movement
                        newPosition.x += sin(time * 0.5 + position.y * 0.2) * 0.02;
                        newPosition.y += cos(time * 0.4 + position.x * 0.2) * 0.02;

                        // Audio-reactive waves
                        float wave = sin((newPosition.x + newPosition.y) * 4.0 - lastAudioImpulse * 10.0) * peakLevel * 0.2;
                        newPosition.z += wave;

                        vec4 mvPosition = modelViewMatrix * vec4(newPosition, 1.0);
                        gl_PointSize = 2.0 * (1.0 + peakLevel * 2.0);
                        gl_Position = projectionMatrix * mvPosition;
                    }
                `,
                fragmentShader: `
                    uniform float time;
                    uniform float avgAudioLevel;
                    uniform float peakLevel;
                    uniform sampler2D audioData;
                    varying vec2 vUv;
                    varying float vRandomness;

                    void main() {
                        float r = length(gl_PointCoord - vec2(0.5));
                        if (r > 0.5) discard;

                        vec2 uv = vUv;
                        float audioValue = texture2D(audioData, vec2(abs(uv.x), 0.5)).r;

                        vec3 baseColor = mix(vec3(0.8), vec3(0.0, 0.5, 1.0), avgAudioLevel);
                        vec3 peakColor = vec3(1.0, 0.0, 0.0);
                        
                        vec3 finalColor = mix(baseColor, peakColor, pow(audioValue * peakLevel, 3.0));
                        
                        // Add some noise
                        finalColor += vec3(vRandomness * 0.1);

                        gl_FragColor = vec4(finalColor, 1.0);
                    }
                `,
                transparent: true,
                blending: THREE.AdditiveBlending,
            });

            particles = new THREE.Points(geometry, material);
            scene.add(particles);

            camera.position.z = 2;

            renderer.domElement.addEventListener('click', toggleFullScreen);
            initAudio();
            animate();
        }

        function animate() {
            requestAnimationFrame(animate);
            time += 0.01;
            particles.material.uniforms.time.value = time;

            if (analyser) {
                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                analyser.getByteFrequencyData(dataArray);
                
                if (!audioData) {
                    audioData = new THREE.DataTexture(dataArray, 256, 1, THREE.RedFormat);
                }
                audioData.needsUpdate = true;
                particles.material.uniforms.audioData.value = audioData;

                const instantAvg = dataArray.reduce((a, b) => a + b, 0) / dataArray.length / 255;
                avgAudioLevel = avgAudioLevel * 0.95 + instantAvg * 0.05;
                const instantPeak = Math.max(...dataArray) / 255;
                peakLevel = Math.max(peakLevel * 0.95, instantPeak);

                // Detect significant audio impulses
                if (instantPeak > peakLevel * 1.5) {
                    lastAudioImpulse = time;
                }

                particles.material.uniforms.avgAudioLevel.value = avgAudioLevel;
                particles.material.uniforms.peakLevel.value = peakLevel;
                particles.material.uniforms.lastAudioImpulse.value = lastAudioImpulse;

                // Decay peak level over time
                peakLevel *= 0.98;
            }

            renderer.render(scene, camera);
        }

        function toggleFullScreen() {
            if (!document.fullscreenElement) {
                document.documentElement.requestFullscreen();
            } else {
                if (document.exitFullscreen) {
                    document.exitFullscreen();
                }
            }
        }

        function initAudio() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    analyser = audioContext.createAnalyser();
                    analyser.fftSize = 512;
                    const source = audioContext.createMediaStreamSource(stream);
                    source.connect(analyser);
                })
                .catch(err => console.error('Fejl ved adgang til mikrofon:', err));
        }

        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
            particles.material.uniforms.resolution.value.set(window.innerWidth, window.innerHeight);
        });

        init();
    </script>
</body>
</html>
