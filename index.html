<!DOCTYPE html>
<html lang="da">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ekstremt Dynamisk TV-sne</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: black; }
        canvas { display: block; }
    </style>
</head>
<body>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script>
        let scene, camera, renderer, particles;
        let audioContext, analyser;
        const particleCount = 300000;
        let audioData, time = 0;
        let avgAudioLevel = 0;
        let peakLevel = 0;

        function init() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer();
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            const geometry = new THREE.BufferGeometry();
            const positions = new Float32Array(particleCount * 3);
            const randomness = new Float32Array(particleCount);

            for (let i = 0; i < particleCount * 3; i += 3) {
                positions[i] = (Math.random() - 0.5) * 4;
                positions[i + 1] = (Math.random() - 0.5) * 4;
                positions[i + 2] = (Math.random() - 0.5) * 4;
                randomness[i / 3] = Math.random();
            }

            geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
            geometry.setAttribute('randomness', new THREE.BufferAttribute(randomness, 1));

            const material = new THREE.ShaderMaterial({
                uniforms: {
                    audioData: { value: null },
                    time: { value: 0 },
                    avgAudioLevel: { value: 0 },
                    peakLevel: { value: 0 },
                    baseMovement: { value: 0.002 },
                    audioInfluence: { value: 0.05 }
                },
                vertexShader: `
                    uniform float time;
                    uniform sampler2D audioData;
                    uniform float avgAudioLevel;
                    uniform float peakLevel;
                    uniform float baseMovement;
                    uniform float audioInfluence;
                    attribute float randomness;
                    varying vec3 vColor;

                    float noise(vec3 p) {
                        return fract(sin(dot(p, vec3(12.9898, 78.233, 45.5432))) * 43758.5453);
                    }

                    void main() {
                        float audioValue = texture2D(audioData, vec2(abs(position.x) * 0.25, 0.5)).r;
                        
                        vec3 newPosition = position;
                        float noiseValue = noise(position * 2.0 + time);
                        
                        // Base movement
                        newPosition += vec3(
                            sin(time * (3.0 + randomness * 2.0) + position.x * 5.0),
                            cos(time * (2.0 + randomness * 2.0) + position.y * 4.0),
                            sin(time * (2.5 + randomness * 2.0) + position.z * 4.5)
                        ) * baseMovement;
                        
                        // Extreme audio-reactive movement
                        float reactiveAudio = audioValue * peakLevel * 10.0;  // Amplify the effect
                        newPosition += vec3(
                            sin(reactiveAudio * 20.0 + time * 10.0),
                            cos(reactiveAudio * 15.0 + time * 8.0),
                            sin(reactiveAudio * 18.0 + time * 9.0)
                        ) * audioInfluence * (1.0 + peakLevel * 5.0);  // Further amplify based on peak

                        // Pulsating effect
                        newPosition *= 1.0 + sin(time * 10.0) * avgAudioLevel * 0.2;

                        // Wrap-around effect
                        newPosition = fract(newPosition + 0.5) - 0.5;
                        newPosition *= 4.0;

                        vec4 mvPosition = modelViewMatrix * vec4(newPosition, 1.0);
                        gl_PointSize = 2.0 * (1.0 + audioValue * 5.0 + noiseValue * peakLevel * 3.0);
                        gl_Position = projectionMatrix * mvPosition;

                        // Dynamic color based on audio level
                        vec3 baseColor = mix(vec3(1.0), vec3(0.0, 0.5, 1.0), avgAudioLevel);  // White to blue
                        vec3 peakColor = vec3(1.0, 0.0, 0.0);  // Red for peaks
                        vColor = mix(baseColor, peakColor, pow(audioValue * peakLevel, 3.0));
                    }
                `,
                fragmentShader: `
                    varying vec3 vColor;
                    void main() {
                        float r = length(gl_PointCoord - vec2(0.5));
                        if (r > 0.5) discard;
                        gl_FragColor = vec4(vColor, 1.0);
                    }
                `,
                transparent: true,
                blending: THREE.AdditiveBlending,
            });

            particles = new THREE.Points(geometry, material);
            scene.add(particles);

            camera.position.z = 2;

            renderer.domElement.addEventListener('click', toggleFullScreen);
            initAudio();
            animate();
        }

        function animate() {
            requestAnimationFrame(animate);
            time += 0.01;
            particles.material.uniforms.time.value = time;

            if (analyser) {
                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                analyser.getByteFrequencyData(dataArray);
                
                if (!audioData) {
                    audioData = new THREE.DataTexture(dataArray, 256, 1, THREE.RedFormat);
                }
                audioData.needsUpdate = true;
                particles.material.uniforms.audioData.value = audioData;

                // Calculate average and peak levels
                const instantAvg = dataArray.reduce((a, b) => a + b, 0) / dataArray.length / 255;
                avgAudioLevel = avgAudioLevel * 0.95 + instantAvg * 0.05;
                const instantPeak = Math.max(...dataArray) / 255;
                peakLevel = Math.max(peakLevel * 0.95, instantPeak);

                particles.material.uniforms.avgAudioLevel.value = avgAudioLevel;
                particles.material.uniforms.peakLevel.value = peakLevel;
                particles.material.uniforms.audioInfluence.value = 0.05 + peakLevel * 0.2;

                // Decay peak level over time
                peakLevel *= 0.98;
            }

            renderer.render(scene, camera);
        }

        function toggleFullScreen() {
            if (!document.fullscreenElement) {
                document.documentElement.requestFullscreen();
            } else {
                if (document.exitFullscreen) {
                    document.exitFullscreen();
                }
            }
        }

        function initAudio() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    analyser = audioContext.createAnalyser();
                    analyser.fftSize = 512;
                    const source = audioContext.createMediaStreamSource(stream);
                    source.connect(analyser);
                })
                .catch(err => console.error('Fejl ved adgang til mikrofon:', err));
        }

        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

        init();
    </script>
</body>
</html>
